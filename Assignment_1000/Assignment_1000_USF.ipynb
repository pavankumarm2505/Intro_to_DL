{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavankumarm2505/Intro_to_DL/blob/main/Assignment_1000/Assignment_1000_USF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C4rdQxKP7UT"
      },
      "source": [
        "# IST597 :Recurrent Neural Networks (RNNs) for sequence classification\n",
        "# Assignment 1000\n",
        "# Author:- Dr. Ankur Mali\n",
        "# Material designed for undergrad course on Deep Learning at USF\n",
        "\n",
        "We will be  building a RNN for sentiment analysis on IMDB movie reviews ( [stanford_imdb](https://https://ai.stanford.edu/~amaas/data/sentiment/)). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All necessary/required files are provided in the github folder. Download them and use it accordingly.\n",
        "## Start late and you won't be able to complete this assignment\n",
        "\n",
        "\n",
        "1. In this assignment you will learn about RNNs and how they can be used to perform sequence classification on IMDB dataset.\n",
        "2. I have created the code to train LSTM and RNN, similar to assignment 3 you will to some analysis on this assignment\n",
        "\n",
        "<font color='red'>Top 10 students, that complete this assignment and get highest accuracy on both RNN and LSTM will get some extra credits. To get extra credits, your assignments should be complete and bug free. </font>\n",
        "\n",
        "Now let's look at few tasks\n",
        "\n",
        "1. Both RNN and LSTM currently overfit the dataset. Your job is to avoid this overfitting\n",
        "\n",
        "# <font color='blue'>Task-1 - Regularization </font>\n",
        "\n",
        "1. Implement L1 or L2 regularization to avoid overfitting -- You can use inbuild function to achieve this\n",
        "2. Use dropout to avoid overfitting -- Remember you don't use dropout during validation and testing phase, thus one needs to switch it off during evaluation phase\n",
        "3. Compared L1/L2 with dropout. Explain which one is better and why\n",
        "4. Create predict function, similar to assignment-3 -- adapt it from the fit function.\n",
        "\n",
        "# <font color='blue'>Things to report </font>\n",
        "1. Perform hyper-parameter optimization. You will have 4 models, RNN + L1/L2, RNN + Dropout, LSTM + L1/L2, LSTM + Dropout -- minimum 4 settings per model\n",
        "2. Once you find your best model, train your model for minimum - 20 epochs\n",
        "3. Finally repeat this for min 5 trials and report average accuracy and standard error.\n",
        "4. For all 4 models, report confusion matrix -- Confusion matrix is calculated over 5 trials, thus mean over 5 trials\n",
        "5. Beside this, you will also report F1, precision and recall -- All these 3 metrics are measured over 5 trials, hence should be mean across trials.\n",
        "\n",
        "# <font color='red'> Rubric </font>\n",
        "1. If only one regularization is used (<font color='red'>-4 points</font>)\n",
        "2. Confusion matrix only reported for 1 trial (<font color='red'>-2 points</font>)\n",
        "3. Confusion matrix not implemented and reported (<font color='red'>-3 points</font>)\n",
        "4. F1,precisio and recall metrics missing (<font color='red'>-2 points</font>)\n",
        "5. Hyper-parameter optimization table missing (<font color='red'>-3 points</font>)\n",
        "6. No results on LSTM or RNN (<font color='red'>-6 points</font>)\n"
      ],
      "metadata": {
        "id": "kvBIRwF8J1g7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rvcyRuYbP7UV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "tf.random.set_seed(16112)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ur6a2Sw5WJjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dbdf423-6c32-4bf0-f23f-fe5b71d7b901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(1,'/content/')\n",
        "from data_utils import parse_imdb_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "CMNILJ0PP7UW",
        "outputId": "6d8188aa-7007-4f0a-9b1d-676adf31acc4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "length_reviews = pickle.load(open('/content/length_reviews.pkl', 'rb'))\n",
        "pd.DataFrame(length_reviews, columns=['Length reviews']).hist(bins=100, color='blue');\n",
        "plt.grid(False);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_train_dataset = tf.data.TFRecordDataset('/content/train.tfrecords')\n",
        "full_train_dataset = full_train_dataset.shuffle(buffer_size=1000)\n",
        "DATASET_SIZE = 25000\n",
        "train_size = int(0.9 * DATASET_SIZE)\n",
        "val_size = int(0.1 * DATASET_SIZE)\n",
        "train_dataset = full_train_dataset.take(train_size)\n",
        "val_dataset = full_train_dataset.skip(train_size)"
      ],
      "metadata": {
        "id": "PywOTZBrVbxT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry15dvJGZZKe",
        "outputId": "6d99c395-cea5-454d-8364-a83c70fd60dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_TakeDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n",
            "<_SkipDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ijVfbU9jP7UY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c459b8-b6e8-4a99-d544-ad17a902bcf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PaddedBatchDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "train_dataset = train_dataset.map(parse_imdb_sequence).shuffle(buffer_size=10000)\n",
        "train_dataset = train_dataset.padded_batch(2048, padded_shapes=([None],[],[]))\n",
        "val_dataset = val_dataset.map(parse_imdb_sequence).shuffle(buffer_size=1000)\n",
        "val_dataset = val_dataset.padded_batch(2048, padded_shapes=([None],[],[]))\n",
        "test_dataset = tf.data.TFRecordDataset('/content/test.tfrecords')\n",
        "test_dataset = test_dataset.map(parse_imdb_sequence).shuffle(buffer_size=10000)\n",
        "test_dataset = test_dataset.padded_batch(512, padded_shapes=([None],[],[]))\n",
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-0boPqdDP7UY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Read the word vocabulary\n",
        "word2idx = pickle.load(open('/content/word2idx.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jVOSepgP7UY"
      },
      "source": [
        "## RNN model for sequence classification, compatible with Eager API \n",
        "----\n",
        "In the cell below, you can find the class that I have created for the RNN model. The API is very similar with one I created in the previous tutorial, except that now we track the accuracy of the model instead of the loss.\n",
        "\n",
        "The idea of the network is very simple. We simply take each word in the review, select its corresponding word embedding (initialized randomly in the beginning), and pass it through the RNN cell. We then take the output of the RNN cell at the end of the sequence and pass it through a dense layer (with ReLU activation) to obtain the final predictions. \n",
        "\n",
        "Like usually, the network inherits from tf.keras.Model in order to keep track of all variables and save/restore them easily.\n",
        "\n",
        "![img](https://github.com/pavankumarm2505/Intro_to_DL/blob/main/Assignment_1000/tutorials_graphics/rnn_imdb.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUoWg4BSP7UY"
      },
      "outputs": [],
      "source": [
        "class RNNModel(tf.keras.Model):\n",
        "    def __init__(self, embedding_size=100, cell_size=64, dense_size=128, \n",
        "                 num_classes=2, vocabulary_size=None, rnn_cell='lstm',\n",
        "                 device='cpu:0', checkpoint_directory=None, checkpoint_prefix = None):\n",
        "        ''' Define the parameterized layers used during forward-pass, the device\n",
        "            where you would like to run the computation on and the checkpoint\n",
        "            directory. Additionaly, you can also modify the default size of the \n",
        "            network.\n",
        "            \n",
        "            Args:\n",
        "                embedding_size: the size of the word embedding.\n",
        "                cell_size: RNN cell size.\n",
        "                dense_size: the size of the dense layer.\n",
        "                num_classes: the number of labels in the network.\n",
        "                vocabulary_size: the size of the word vocabulary.\n",
        "                rnn_cell: string, either 'lstm' or 'ugrnn'.\n",
        "                device: string, 'cpu:n' or 'gpu:n' (n can vary). Default, 'cpu:0'.\n",
        "                checkpoint_directory: the directory where you would like to save or \n",
        "                                      restore a model.\n",
        "        '''\n",
        "        super(RNNModel, self).__init__()\n",
        "        \n",
        "        # Weights initializer function\n",
        "        w_initializer = tf.compat.v1.keras.initializers.glorot_uniform()\n",
        "    \n",
        "        # Biases initializer function\n",
        "        b_initializer = tf.zeros_initializer()\n",
        "        \n",
        "        # Initialize weights for word embeddings \n",
        "        self.embeddings = tf.keras.layers.Embedding(vocabulary_size, embedding_size, \n",
        "                                                    embeddings_initializer=w_initializer)\n",
        "        \n",
        "        # Dense layer initialization\n",
        "        self.dense_layer = tf.keras.layers.Dense(dense_size, activation=tf.nn.relu, \n",
        "                                                 kernel_initializer=w_initializer, \n",
        "                                                 bias_initializer=b_initializer,\n",
        "                                                kernel_regularizer = tf.keras.regularizers.l2(0.1))\n",
        "        # self.dense_layer = tf.keras.layers.Dense(dense_size, activation=tf.nn.relu, \n",
        "        #                                          kernel_initializer=w_initializer, \n",
        "        #                                          bias_initializer=b_initializer)\n",
        "        \n",
        "        # Predictions layer initialization\n",
        "        self.pred_layer = tf.keras.layers.Dense(num_classes, activation=None, \n",
        "                                                kernel_initializer=w_initializer, \n",
        "                                                bias_initializer=b_initializer)\n",
        "        \n",
        "        # Basic LSTM cell\n",
        "        if rnn_cell=='lstm':\n",
        "            self.rnn_cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(cell_size)\n",
        "        # Else RNN cell\n",
        "        else:\n",
        "            self.rnn_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(cell_size)\n",
        "            \n",
        "        # Define the device \n",
        "        self.device = device\n",
        "        \n",
        "        # Define the checkpoint directory\n",
        "        self.checkpoint_directory = checkpoint_directory\n",
        "        self.checkpoint_prefix = checkpoint_prefix\n",
        "        \n",
        "    def predict(self, X, seq_length, is_training):\n",
        "        '''\n",
        "        Predicts the probability of each class, based on the input sample.\n",
        "\n",
        "        Args:\n",
        "            X: 2D tensor of shape (batch_size, time_steps).\n",
        "            seq_length: the length of each sequence in the batch.\n",
        "            is_training: Boolean. Either the network is predicting in\n",
        "                         training mode or not.\n",
        "        '''\n",
        "        \n",
        "        # Get the number of samples within a batch\n",
        "        num_samples = tf.shape(X)[0]\n",
        "\n",
        "        # Initialize LSTM cell state with zeros\n",
        "        state = self.rnn_cell.zero_state(num_samples, dtype=tf.float32)\n",
        "        \n",
        "        # Get the embedding of each word in the sequence\n",
        "        embedded_words = self.embeddings(X)\n",
        "        \n",
        "        # Unstack the embeddings\n",
        "        unstacked_embeddings = tf.unstack(embedded_words, axis=1)\n",
        "        \n",
        "        # Iterate through each timestep and append the predictions\n",
        "        outputs = []\n",
        "        for input_step in unstacked_embeddings:\n",
        "            output, state = self.rnn_cell(input_step, state)\n",
        "            outputs.append(output)\n",
        "            \n",
        "        # Stack outputs to (batch_size, time_steps, cell_size)\n",
        "        outputs = tf.stack(outputs, axis=1)\n",
        "        \n",
        "        # Extract the output of the last time step, of each sample\n",
        "        idxs_last_output = tf.stack([tf.range(num_samples), \n",
        "                                     tf.cast(seq_length-1, tf.int32)], axis=1)\n",
        "        final_output = tf.gather_nd(outputs, idxs_last_output)\n",
        "        \n",
        "        # from tensorflow.keras.layers import Dropout\n",
        "        # # # Add dropout for regularization\n",
        "        # dropped_output = Dropout(rate=0.3)(final_output, training=is_training)\n",
        "        \n",
        "        # Pass the last cell state through a dense layer (ReLU activation)\n",
        "        dense = self.dense_layer(final_output)\n",
        "        # dense = self.dense_layer(dropped_output)\n",
        "        # Compute the unnormalized log probabilities\n",
        "        logits = self.pred_layer(dense)\n",
        "        return logits\n",
        "\n",
        "    @tf.function\n",
        "    def loss_fn(self, X, y, seq_length, is_training):\n",
        "        \"\"\" Defines the loss function used during \n",
        "            training.         \n",
        "        \"\"\"\n",
        "        preds = self.predict(X, seq_length, is_training)\n",
        "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=preds)\n",
        "        return loss\n",
        "\n",
        "    \n",
        "    @tf.function\n",
        "    def grads_fn(self, X, y, seq_length, is_training):\n",
        "        \"\"\" Dynamically computes the gradients of the loss value\n",
        "            with respect to the parameters of the model, in each\n",
        "            forward pass.\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self.loss_fn(X, y, seq_length, is_training)\n",
        "        return tape.gradient(loss, self.variables)\n",
        "\n",
        "    \n",
        "    @tf.function\n",
        "    def restore_model(self):\n",
        "        \"\"\" Function to restore trained model.\n",
        "        \"\"\"\n",
        "        with tf.device(self.device):\n",
        "            # Run the model once to initialize variables\n",
        "            dummy_input = tf.constant(tf.zeros((1,1)))\n",
        "            dummy_length = tf.constant(1, shape=(1,))\n",
        "            dummy_pred = self.predict(dummy_input, dummy_length, False)\n",
        "            # Restore the variables of the model\n",
        "            saver = tf.compat.v1.train.Saver(self.variables)\n",
        "            saver.restore(tf.train.latest_checkpoint\n",
        "                          (self.checkpoint_directory))\n",
        "    @tf.function\n",
        "    def save_model(self, global_step=0):\n",
        "        \"\"\" Function to save trained model.\n",
        "        \"\"\"\n",
        "        tf.compat.v1.train.Saver(self.variables).save(save_path=self.checkpoint_directory, \n",
        "                                       global_step=global_step)   \n",
        "        \n",
        "    def fit(self, training_data, eval_data, optimizer, num_epochs=500, \n",
        "            early_stopping_rounds=10, verbose=10, train_from_scratch=False, ckpoint=None):\n",
        "        \"\"\" Function to train the model, using the selected optimizer and\n",
        "            for the desired number of epochs. You can either train from scratch\n",
        "            or load the latest model trained. Early stopping is used in order to\n",
        "            mitigate the risk of overfitting the network.\n",
        "            \n",
        "            Args:\n",
        "                training_data: the data you would like to train the model on.\n",
        "                                Must be in the tf.data.Dataset format.\n",
        "                eval_data: the data you would like to evaluate the model on.\n",
        "                            Must be in the tf.data.Dataset format.\n",
        "                optimizer: the optimizer used during training.\n",
        "                num_epochs: the maximum number of iterations you would like to \n",
        "                            train the model.\n",
        "                early_stopping_rounds: stop training if the accuracy on the eval \n",
        "                                       dataset does not increase after n epochs.\n",
        "                verbose: int. Specify how often to print the loss value of the network.\n",
        "                train_from_scratch: boolean. Whether to initialize variables of the\n",
        "                                    the last trained model or initialize them\n",
        "                                    randomly.\n",
        "        \"\"\" \n",
        "    \n",
        "        if train_from_scratch==False:\n",
        "            self.restore_model()\n",
        "        \n",
        "        # Initialize best_acc. This variable will store the highest accuracy\n",
        "        # on the eval dataset.\n",
        "        best_acc = 0\n",
        "        \n",
        "        # Initialize classes to update the mean accuracy of train and eval\n",
        "        train_acc = tf.keras.metrics.Accuracy('train_acc')\n",
        "        eval_acc = tf.keras.metrics.Accuracy('eval_acc')\n",
        "        \n",
        "        \n",
        "        # Initialize dictionary to store the accuracy history\n",
        "        self.history = {}\n",
        "        self.history['train_acc'] = []\n",
        "        self.history['eval_acc'] = []\n",
        "        \n",
        "        # Begin training\n",
        "        with tf.device(self.device):\n",
        "            for i in range(num_epochs):\n",
        "                # Training with gradient descent\n",
        "                for step, (X, y, seq_length) in enumerate(training_data):\n",
        "                    grads = self.grads_fn(X, y, seq_length, True)\n",
        "                    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "                    \n",
        "                # Check accuracy train dataset\n",
        "                for step, (X, y, seq_length) in enumerate(training_data):\n",
        "                    logits = self.predict(X, seq_length, False)\n",
        "                    logits = tf.nn.softmax(logits)\n",
        "                    preds = tf.argmax(logits, axis=1)\n",
        "                    train_acc(preds, y)\n",
        "                self.history['train_acc'].append(train_acc.result().numpy())\n",
        "                # Reset metrics\n",
        "                train_acc.reset_states()\n",
        "\n",
        "                # Check accuracy eval dataset\n",
        "                for step, (X, y, seq_length) in enumerate(eval_data):\n",
        "                    logits = self.predict(X, seq_length, False)\n",
        "                    logits = tf.nn.softmax(logits)\n",
        "                    preds = tf.argmax(logits, axis=1)\n",
        "                    eval_acc(preds, y)\n",
        "                self.history['eval_acc'].append(eval_acc.result().numpy())\n",
        "                # Reset metrics\n",
        "                eval_acc.reset_states()\n",
        "                \n",
        "                # Print train and eval accuracy\n",
        "                if (i==0) | ((i+1)%verbose==0):\n",
        "                    print('Train accuracy at epoch %d: ' %(i+1), self.history['train_acc'][-1])\n",
        "                    print('Eval accuracy at epoch %d: ' %(i+1), self.history['eval_acc'][-1])\n",
        "                    ckpoint.save(file_prefix=self.checkpoint_prefix)\n",
        "\n",
        "                # Check for early stopping\n",
        "                if self.history['eval_acc'][-1]>best_acc:\n",
        "                    best_acc = self.history['eval_acc'][-1]\n",
        "                    count = early_stopping_rounds\n",
        "                else:\n",
        "                    count -= 1\n",
        "                if count==0:\n",
        "                    break  \n",
        "    def predict_fc(self, test_data):\n",
        "      # Initialize classes to update the mean loss of train and eval\n",
        "        \n",
        "        test_acc = tf.keras.metrics.Mean('test_acc')\n",
        "        self.history = {}\n",
        "        self.history['test_acc'] = []\n",
        "        \n",
        "        # Begin training\n",
        "        with tf.device(self.device):\n",
        "          for step, (X, y, seq_length) in enumerate(test_data):\n",
        "                    logits = self.predict(X, seq_length, False)\n",
        "                    logits = tf.nn.softmax(logits)\n",
        "                    preds = tf.argmax(logits, axis=1)\n",
        "                    test_acc(preds, y)\n",
        "          self.history['test_acc'].append(test_acc.result().numpy())\n",
        "        print(\"test_accuracy %d\", test_acc.result())\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq07GFNrP7UZ"
      },
      "source": [
        "## Train model with gradient descent and early stopping\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIuGUj5CP7UZ"
      },
      "source": [
        "### Model training with simple RNN cells\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqk_DJZ3P7Ua"
      },
      "outputs": [],
      "source": [
        "# Specify the path where you want to save/restore the trained variables.\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "checkpoint_directory = '/content/models_checkpoints/ImdbRNN/'\n",
        "checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt\")\n",
        "\n",
        "# Use the GPU if available.\n",
        "device = 'gpu:0'\n",
        "\n",
        "# Define optimizer.\n",
        "optimizer = tf.compat.v1.train.RMSPropOptimizer(learning_rate=1e-4)\n",
        "\n",
        "# Instantiate model. This doesn't initialize the variables yet.\n",
        "rnn_model = RNNModel(vocabulary_size=len(word2idx), rnn_cell='rnn', device=device,\n",
        "                      checkpoint_directory=checkpoint_directory, checkpoint_prefix = checkpoint_prefix)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=rnn_model)\n",
        "checkpoint.save(file_prefix=checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXvPU8_gP7Ua"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "rnn_model.fit(train_dataset,val_dataset, optimizer, num_epochs=20, \n",
        "                early_stopping_rounds=5, verbose=1, train_from_scratch=True, ckpoint = checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Create a predict function and test on test_dataset for RNN\n",
        "# TODO\n",
        "\n",
        "##created the function in the RNN model."
      ],
      "metadata": {
        "id": "wls4vS77a2Go"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.predict_fc(test_dataset)"
      ],
      "metadata": {
        "id": "BY60vAl89WIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['positive','negative']\n",
        "\n",
        "from typing import List, Optional, Sequence\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(\n",
        "    true: np.ndarray,\n",
        "    pred: np.ndarray,\n",
        "    labels: Optional[List[str]] = None,\n",
        "    normalize: str = \"true\",\n",
        "    figsize: Sequence[int] = (5, 4),\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Plot confusion matrix\n",
        "    Args:\n",
        "        true (numpy.array): true label\n",
        "        pred (numpy.array): predicted label\n",
        "        labels (List[str]), default=None] list of label names\n",
        "        normalize (str, default=\"true): whether to normalize scores, chosen from \"true\" or \"false\"\n",
        "    Returns:\n",
        "        fig: figure of confusion matrix\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(true, pred, normalize=normalize)\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        cmap=\"Blues\",\n",
        "        square=True,\n",
        "        vmin=0,\n",
        "        vmax=1.0,\n",
        "        xticklabels=labels,\n",
        "        yticklabels=labels,\n",
        "    )\n",
        "    plt.xlabel(\"Predicted label\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    plt.title(\"Normalized confusion matrix\")\n",
        "\n",
        "    plt.close()\n",
        "    return fig"
      ],
      "metadata": {
        "id": "z-BuUQwjEUAm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A0gIM18TEgal"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_test_samples = tf.data.Dataset.cardinality(test_dataset)\n",
        "\n",
        "\n",
        "test_dataset = test_dataset.shuffle(buffer_size=1000)\n",
        "average=np.zeros((25000, 1))\n",
        "\n",
        "final_out = np.array([])\n",
        "reshaped_array = np.array([])\n",
        "\n",
        "\n",
        "for (X, y, seq_length) in test_dataset:\n",
        "\n",
        "   \n",
        "    preds = rnn_model.predict(X, seq_length, False)\n",
        "\n",
        "    \n",
        "    preds = tf.nn.softmax(preds)\n",
        "\n",
        "    \n",
        "    predicted_label = tf.argmax(preds, axis=1)\n",
        "\n",
        "    \n",
        "    final_out = np.concatenate([final_out, predicted_label], axis=0)\n",
        "\n",
        "    \n",
        "    reshaped_array = np.concatenate([reshaped_array, y], 0)\n",
        "# Plot the confusion matrix\n",
        "concatenated_tensor = tf.convert_to_tensor(final_out,dtype=tf.int64)\n",
        "indices = np.arange(10)\n",
        "predictions = indices[concatenated_tensor.numpy()]\n",
        "average = np.add(average,predictions)"
      ],
      "metadata": {
        "id": "9-TipjozEkCS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.sparse as sp\n",
        "\n",
        "new_average = sp.csr_matrix(average)\n",
        "new_average = new_average/5.0\n",
        "average = new_average.toarray()"
      ],
      "metadata": {
        "id": "SwV-KEp5QxyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(reshaped_array, final_out, labels=class_names, figsize=(4, 4))"
      ],
      "metadata": {
        "id": "A_Ev83Cec7-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(reshaped_array, final_out, target_names=class_names))"
      ],
      "metadata": {
        "id": "45IN588kmn8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmzXh0ljP7Ua"
      },
      "source": [
        "### Model training with LSTM cells \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmjyKjDYP7Ub"
      },
      "outputs": [],
      "source": [
        "# Define optimizer.\n",
        "checkpoint_directory = '/content/models_checkpoints/ImdbLSTM/'\n",
        "checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt\")\n",
        "optimizer = tf.compat.v1.train.RMSPropOptimizer(learning_rate=1e-4)\n",
        "# optimizer = tf.compat.v1.train.RMSPropOptimizer(learning_rate=1e-4, decay=0.9, momentum=0.0)\n",
        "\n",
        "# Instantiate model. This doesn't initialize the variables yet.\n",
        "lstm_model = RNNModel(vocabulary_size=len(word2idx), rnn_cell='lstm', \n",
        "                       device=device, checkpoint_directory=checkpoint_directory, checkpoint_prefix = checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd5bDpAzP7Ub"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=lstm_model)\n",
        "checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "lstm_model.fit(train_dataset, val_dataset, optimizer, num_epochs=20, \n",
        "                early_stopping_rounds=5, verbose=1, train_from_scratch=True,ckpoint = checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['positive','negative']\n",
        "\n",
        "from typing import List, Optional, Sequence\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(\n",
        "    true: np.ndarray,\n",
        "    pred: np.ndarray,\n",
        "    labels: Optional[List[str]] = None,\n",
        "    normalize: str = \"true\",\n",
        "    figsize: Sequence[int] = (5, 4),\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Plot confusion matrix\n",
        "    Args:\n",
        "        true (numpy.array): true label\n",
        "        pred (numpy.array): predicted label\n",
        "        labels (List[str]), default=None] list of label names\n",
        "        normalize (str, default=\"true): whether to normalize scores, chosen from \"true\" or \"false\"\n",
        "    Returns:\n",
        "        fig: figure of confusion matrix\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(true, pred, normalize=normalize)\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        cmap=\"Blues\",\n",
        "        square=True,\n",
        "        vmin=0,\n",
        "        vmax=1.0,\n",
        "        xticklabels=labels,\n",
        "        yticklabels=labels,\n",
        "    )\n",
        "    plt.xlabel(\"Predicted label\")\n",
        "    plt.ylabel(\"True label\")\n",
        "    plt.title(\"Normalized confusion matrix\")\n",
        "\n",
        "    plt.close()\n",
        "    return fig"
      ],
      "metadata": {
        "id": "fngl0drvbQGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_test_samples = tf.data.Dataset.cardinality(test_dataset)\n",
        "\n",
        "\n",
        "test_dataset = test_dataset.shuffle(buffer_size=1000)\n",
        "average=np.zeros((25000, 1))\n",
        "\n",
        "final_out = np.array([])\n",
        "reshaped_array = np.array([])\n",
        "\n",
        "# Iterate over the test dataset\n",
        "for (X, y, seq_length) in test_dataset:\n",
        "\n",
        "    \n",
        "    preds = rnn_model.predict(X, seq_length, False)\n",
        "\n",
        "    \n",
        "    preds = tf.nn.softmax(preds)\n",
        "\n",
        "    \n",
        "    predicted_label = tf.argmax(preds, axis=1)\n",
        "\n",
        "    \n",
        "    final_out = np.concatenate([final_out, predicted_label], axis=0)\n",
        "\n",
        "    \n",
        "    reshaped_array = np.concatenate([reshaped_array, y], 0)\n",
        "# Plot the confusion matrix\n",
        "concatenated_tensor = tf.convert_to_tensor(final_out,dtype=tf.int64)\n",
        "indices = np.arange(10)\n",
        "predictions = indices[concatenated_tensor.numpy()]\n",
        "average = np.add(average,predictions)"
      ],
      "metadata": {
        "id": "WxLVDIrSbP9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "new_average = sp.csr_matrix(average)\n",
        "new_average = new_average/5.0\n",
        "average = new_average.toarray()"
      ],
      "metadata": {
        "id": "fEXHLrT5comE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(reshaped_array, final_out, labels=class_names, figsize=(4, 4))"
      ],
      "metadata": {
        "id": "NJM3l4wFcobW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(reshaped_array, final_out, target_names=class_names))"
      ],
      "metadata": {
        "id": "4CtGupO9nBQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HloeEKJP7Ub"
      },
      "source": [
        "### Performance comparison\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Create a predict function and test on test_dataset for LSTM\n",
        "# TODO\n",
        "lstm_model.predict_fc(test_dataset)"
      ],
      "metadata": {
        "id": "5SzvUSWWf3xF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433b6319-dad0-4b4b-a5b2-1fb2347fc23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_accuracy %d tf.Tensor(0.85824, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW-exJpxP7Ub"
      },
      "outputs": [],
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 4))\n",
        "ax1.plot(range(len(lstm_model.history['train_acc'])), lstm_model.history['train_acc'], \n",
        "         label='LSTM Train Accuracy');\n",
        "ax1.plot(range(len(lstm_model.history['eval_acc'])), lstm_model.history['eval_acc'], \n",
        "         label='LSTM Val Accuracy');\n",
        "ax2.plot(range(len(rnn_model.history['train_acc'])), rnn_model.history['train_acc'],\n",
        "         label='RNN Train Accuracy');\n",
        "ax2.plot(range(len(rnn_model.history['eval_acc'])), rnn_model.history['eval_acc'],\n",
        "         label='RNN Val Accuracy');\n",
        "ax1.legend();\n",
        "ax2.legend();\n",
        "\n",
        "\n",
        "### Both Model overfits -- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrMkRP-0P7Ub"
      },
      "source": [
        "## Test network on new samples\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXSOpyz0P7Uc"
      },
      "outputs": [],
      "source": [
        "###############################################################\n",
        "# Import/download necessary libraries to process new sequences\n",
        "###############################################################\n",
        "import nltk\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zDt0vVlP7Uc"
      },
      "outputs": [],
      "source": [
        "def process_new_review(review):\n",
        "    '''Function to process a new review.\n",
        "       Args:\n",
        "           review: original text review, string.\n",
        "       Returns:\n",
        "           indexed_review: sequence of integers, words correspondence \n",
        "                           from word2idx.\n",
        "           seq_length: the length of the review.\n",
        "    '''\n",
        "    indexed_review = re.sub(r'<[^>]+>', ' ', review)\n",
        "    indexed_review = word_tokenize(indexed_review)\n",
        "    indexed_review = [word2idx[word] if word in list(word2idx.keys()) else \n",
        "                      word2idx['Unknown_token'] for word in indexed_review]\n",
        "    indexed_review = indexed_review + [word2idx['End_token']]\n",
        "    seq_length = len(indexed_review)    \n",
        "    return indexed_review, seq_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZmRTbHCP7Uc"
      },
      "outputs": [],
      "source": [
        "sent_dict = {0: 'negative', 1: 'positive'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo8W4xfdP7Uc"
      },
      "outputs": [],
      "source": [
        "review_score_10 = \"I think Bad Apples is a great time and I recommend! I enjoyed the opening, which gave way for the rest of the movie to occur. The main couple was very likable and I believed all of their interactions. They had great onscreen chemistry and made me laugh quite a few times! Keeping the girls in the masks but seeing them in action was something I loved. It kept a mystery to them throughout. I think the dialogue was great. The kills were fun. And the special surprise gore effect at the end was AWESOME!! I won't spoil that part ;) I also enjoyed how the movie wrapped up. It gave a very urban legends type feel of \\\"did you ever hear the story...\\\". Plus is leaves the door open for another film which I wouldn't mind at all. Long story short, I think if you take the film for what it is; a fun little horror flick, then you won't be disappointed! HaPpY eArLy HaLLoWeEn!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL2PWrzPP7Uc"
      },
      "outputs": [],
      "source": [
        "review_score_4 = \"A young couple comes to a small town, where the husband get a job working in a hospital. The wife which you instantly hate or dislike works home, at the same time a horrible murders takes place in this small town by two masked killers. Bad Apples is just your tipical B-horror movie with average acting (I give them that. Altough you may get the idea that some of the actors are crazy-convervative Christians), but the script is just bad, and that's what destroys the film.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGJG7F6kP7Uc"
      },
      "outputs": [],
      "source": [
        "review_score_1 = \"When you first start watching this movie, you can tell its going to be a painful ride. the audio is poor...the attacks by the \\\"girls\\\" are like going back in time, to watching the old rocky films, were blows never touched. the editing is poor with it aswell, example the actress in is the bath when her husband comes home, clearly you see her wearing a flesh coloured bra in the bath. no hints or spoilers, just wait till you find it in a bargain basket of cheap dvds in a couple of weeks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-hrh4LCP7Ud"
      },
      "outputs": [],
      "source": [
        "new_reviews = [review_score_10, review_score_4, review_score_1]\n",
        "scores = [10, 4, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvVuzgTwP7Ud",
        "outputId": "352b6546-839f-4e00-9b78-3bc0684d91c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment for the review with score 10 was found to be positive\n",
            "The sentiment for the review with score 4 was found to be negative\n",
            "The sentiment for the review with score 1 was found to be negative\n"
          ]
        }
      ],
      "source": [
        "## With LSTM\n",
        "\n",
        "with tf.device(device):\n",
        "    for original_review, score in zip(new_reviews, scores):\n",
        "        indexed_review, seq_length = process_new_review(original_review)\n",
        "        indexed_review = tf.reshape(tf.constant(indexed_review), (1,-1))\n",
        "        seq_length = tf.reshape(tf.constant(seq_length), (1,))\n",
        "        logits = lstm_model.predict(indexed_review, seq_length, False)\n",
        "        logits = tf.nn.softmax(logits)\n",
        "        pred = tf.argmax(logits, axis=1).numpy()[0]\n",
        "        print('The sentiment for the review with score %d was found to be %s'\n",
        "              %(score, sent_dict[pred]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## With RNN\n",
        "\n",
        "with tf.device(device):\n",
        "    for original_review, score in zip(new_reviews, scores):\n",
        "        indexed_review, seq_length = process_new_review(original_review)\n",
        "        indexed_review = tf.reshape(tf.constant(indexed_review), (1,-1))\n",
        "        seq_length = tf.reshape(tf.constant(seq_length), (1,))\n",
        "        logits = rnn_model.predict(indexed_review, seq_length, False)\n",
        "        logits = tf.nn.softmax(logits)\n",
        "        pred = tf.argmax(logits, axis=1).numpy()[0]\n",
        "        print('The sentiment for the review with score %d was found to be %s'\n",
        "              %(score, sent_dict[pred]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrUvYrdpt_SI",
        "outputId": "4c3afec4-7048-4cb4-a8d2-08d7963b6581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment for the review with score 10 was found to be positive\n",
            "The sentiment for the review with score 4 was found to be negative\n",
            "The sentiment for the review with score 1 was found to be negative\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}